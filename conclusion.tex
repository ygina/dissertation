\chapter{Conclusion}
\label{sec:conclusion}

This dissertation explored a new approach to resolving the tension between
performance and ossification for secure transport protocols. This tension
emerged over the last few decades starting with the growth of wireless networks
and lossy, high-delay paths. TCP performance-enhancing proxies were deployed to
ameliorate the poor performance of ``loss-based'' congestion control algorithms
such as CUBIC in these settings, but PEPs have since become controversial for
preventing existing transport protocols from evolving on the wire. This led to
the deployment of ``secure'' transport protocols such as QUIC that encrypt
their transport headers and forgo all proxy assistance.

In the \textbf{Sidekick} approach to in-network assistance, proxies and
endpoints send information on an \textit{adjacent} connection to the base
connection \textit{about} the encrypted packets that they have received. This
information is called the \textbf{quACK}, applying set reconciliation
techniques to be able to efficiently refer to random identifiers even at
packet-scale settings (\Cref{sec:quack}). When proxies and endpoints send
quACKs using the Sidekick protocol (\Cref{sec:sidekick}) or Packrat protocol
(\Cref{sec:packrat}), we find that secure transport protocols are able to
achieve performance benefits similar to those achieved by TCP using traditional
PEPs. These benefits include earlier retransmissions, path-aware congestion
responses, reduced energy usage at the endpoint, and reduced network
congestion---all without modifying the wire format nor the packets of the
underlying connection.

At times, it seems the world has already moved on from PEPs, designing new
congestion control algorithms and transport protocols to supplant those of the
1990s connection-splitting era. But this dissertation has shown that even the
latest ``model-based'' BBR algorithm remains vulnerable to lossy networks---and
that in some network conditions, at least in emulation, proxies still
significantly improve the long-lived throughput of modern QUIC
(\Cref{sec:splitting}). In-network assistance from proxies continues to offer
valuable performance benefits, but will we have learned our lesson about
ossification? The Sidekick approach is one such proposal for reconciling the
two. I hope this work encourages efforts to better establish the scope of this
problem in real-world deployments, and to design more practical, deployable
methods that reimagine how endpoints and the network can securely collaborate.

\section{Discussion on real-world studies and deployment}
\label{sec:conclusion:real-world}

After the publication of our NSDI '24 paper~\cite{yuan2024sidekick}, we
presented this work to various stakeholders in industry (Google, satellite and
cellular network operators) and the Internet standards community at the IETF to
gauge whether there was any practical interest. Here, I summarize some of my
main takeaways and my view on the obstacles that must be overcome for such a
proposal to come to life.
% In the end, I do not imagine the Sidekick protocol becoming widely deployed.
% Though widespread adoption of Sidekick was never really the goal in conducting
% this research, here I summarize some of my takeaways on some of the obstacles
% that prevent a proposal about the Internet from coming to life.

\subsubsection{Do these stakeholders believe a problem exists and needs to be
 solved?}

When we first approached industry with this problem about in-network assistance
for secure transport protocols, we faced some skepticism about its premise.
For example, studies from Google showed that QUIC empirically matched or
exceeded TCP's performance in wide deployment~\cite{langley2017quic}, and others
believed that BBR's minimization of loss as a congestion signal meant that
connection-splitting was no longer relevant~\cite{frode}. This inspired us to
perform the measurement study in
\Cref{sec:splitting}, which showed that BBR's behavior has evolved to benefit
more from splitting over time and that perhaps the empirical studies of QUIC
are missing certain less-studied classes of network settings.

Network operators provided mixed feedback despite widely deploying PEPs
themselves. Cellular operators described link-layer retransmissions as
rendering loss virtually nonexistent. On the other hand, satellite network
operators were extremely enthusiastic. It is a valid concern that Sidekick
only benefits network settings with random loss, though \Cref{sec:packrat}
evaluates some of the tradeoffs with link-layer approaches. Real-world studies
in collaboration with network operators are required to truly understand the
scope of the problem in practice. It would be valuable to look at both networks
where PEPs are currently deployed (Class I in \Cref{sec:splitting}), as well as
satellite, wireless ad-hoc, and other networks where reliable connectivity is
still an unsolved problem (Classes II and III).

There must also be personal incentives for transport protocol developers and
network operators to deploy a solution, even if they believe the problem
exists. Network operators want their users to experience good performance as a
signal of the network quality they pay for. Protocol developers may only care
about good performance that covers a majority of use cases, even if the tail
end suffers.

\subsubsection{If so, do they believe Sidekick protocols are the right
 solution?}

There are risks to deploying new solutions, especially when two independent
parties need to collaborate. Unlike transparent PEPs, Sidekick protocols
require both endpoints and proxies to deploy their half of the solution before
they can observe performance benefits. When deployed unilaterally, the proxy
pays a cost for in-line packet processing, while the endpoint has invested in
integrating the complex coding theory of the quACK into their application. The
status quo is simply easier to maintain.

Another risk is that the performance of Sidekick protocols in the real world is
not well understood. Although \Cref{sec:sidekick:real-world} showed some
empirical promise, the improvements were still less pronounced and more
variable than those in emulation. We hypothesized that these results could be
explained by the greater variability in real networks, and that a dynamically
configured quACK would improve performance. Such improvements can be made
after an initial deployment.

A final obstacle in practice is that there needs to be a protocol standard so
that the endpoint and proxy can communicate with each other when they are
controlled by different entities. We found some common ground with the MASQUE
and SCONEPRO communities at the IETF for signaling in-network information over
an adjacent connection, but ultimately these proposals already had specific
scopes in mind, and the Sidekick proposal had the limitations described here.

One workaround to standardization would be to evaluate Sidekick protocols from
an organization that controls both entities. One such environment would be a
home, office, or public Wi-Fi environment where we could run a proxy on an
in-line device behind the wireless router in a building with clients that we
control. Another environment would be with a business that controls both an
application and some CDN/SFU infrastructure with in-network nodes that can act
as proxies.

\section{Future research directions}
\label{sec:conclusion:future}

Building on the ideas developed in this dissertation, I now explore several
open-ended directions for future research.

\subsubsection{Performance engineering the quACK.}

In \Cref{sec:quack}, we detailed the performance engineering required to make
set reconciliation practical at packet scales, including nanosecond per-packet
overheads and communication sizes under 100 bytes. One limitation of the
current IBLT construction is that decoding with high probability requires
sending significantly more symbols than the number of missing elements,
undermining the rateless property. Future work could explore new mapping
functions or data structures that reduce the chance of collision when decoding
small set sizes, or that consider a known distribution of packet identifiers,
or even an interactive Sidekick protocol that uses more than one RTT for set
reconciliation. Implementing quACK operations in specialized hardware is
another open-ended idea for performance optimization and enabling in-line
quACK processing in high-speed networks.

\subsubsection{Utilizing the quACK in other packet-scale settings.}

Could quACKs prove more broadly useful in other networking scenarios? In \Cref
{sec:sidekick} and \Cref{sec:packrat}, we applied quACKs to Sidekick protocols
so that path-aware endpoints could emulate the behavior of PEPs. However,
quACKs could also be used for network packet analysis, aggregating statistics
in real-time with minimal space and computation. It may also be interesting to
explore the relation of quACKs to data sketches and streaming algorithms, other
research areas at the intersection of networking and coding theory. One
research problem is how to enforce differentiated services~\cite{rfc3260}
based solely on the observed flow behavior, rather than trusting packet
markings. Bloom-filter-like data structures such as the one in the quACK are
especially well-suited to settings like this that demand efficient per-packet
operations with approximate statistics.

\subsubsection{Sending in-network signals over an adjacent connection.}

The general idea of sending in-network signals over an adjacent connection
increases endpoint visibility into the network without altering the underlying
connection. This generates various opportunities to improve performance from
the perspective of the endpoint. A variation on the quACK over the packets that
have been \textit{received} could be a quACK over the packets that have been
\textit{sent}. This would allow the decoder to explicitly refer to missing
packets by their identifiers, an example of another type of path-aware endpoint
behavior enabled by quACKs.

Now imagine an omnipotent scheduler aware of the properties of every path
segment and the application behavior desired by every endpoint in the network.
The signals need not just be quACKs, but could also be the queue policy and
state, the current fair flow rate, ECN, etc. What is a \textit{fair} allocation
of resources with this knowledge and how can we achieve this allocation
(or something close) by signaling information about the network to the
endpoints?

\subsubsection{Multicast and using proxies to benefit the network.}

How can proxies benefit not just applications but the network itself? In most of
this work, we have described the advantages of Sidekick protocols in terms of
application metrics such as throughput and latency. But in-network
retransmissions and reducing the amount of time a connection needs to stay
alive can also reduce network congestion, an understated advantage of PEPs.

In an initial exploration of IP multicast in \Cref{sec:packrat}, we showed that
a modified Packrat proxy can deliver in-network retransmissions to multicast
clients with minimal per-client memory overhead. Multicast inherently reduces
network congestion by reducing redundant data delivery over the network. For
many practical reasons, including reliability, IP multicast is not used over
the Internet today~\cite{diot2000deployment}. It would be interesting to explore
whether a network with some composition of Packrat proxies could enable a more
practical yet reliable form of multicast.

\section{Immediate impact on congestion control research}
\label{sec:conclusion:congestion}

Independent of connection-splitting, the measurement study in
\Cref{sec:splitting} has several implications for congestion control research
even in end-to-end settings. First, we urge researchers to refer
to congestion control schemes by algorithm/implementation/version, not just
``BBR'' or even ``QUIC BBRv1''. The networking community once used ``TCP''
synonymously with its congestion control until many more algorithms evolved.
Times have changed again, and we showed BBR to exhibit significantly different
behavior over major version changes and in the many implementations of QUIC.

Second, we urge the community to create performance test suites for a congestion
control implementation to be able to claim that it conforms to a particular
standard. That is, an implementation should empirically achieve the intended
behavior of the algorithm. The behavior can be described as a relative trend
such as reacting progessively to random loss up to 10\%, or an absolute
behavior such as achieving the maximum bandwidth in a lossless, single-flow
setting. These test suites can include our heatmaps, for example. The goal of
establishing an empirical standard is to help implementations achieve more
similar behavior in the same settings for a fairer Internet, or even to hold
intentionally different implementations accountable and explain the differences.

Finally, the \textit{split throughput heuristic} can be incorporated as a
research tool for studying congestion control in split settings. It is
challenging for QUIC to emulate the behavior of split QUIC connections without
having an explicit connection splitter to benchmark against. The heuristic
helps us understand potential performance benefits based on end-to-end changes
even in theoretical split settings. It gives us a systematic approach to
understanding split behavior when the path is split into multiple segments each
using a different end-to-end scheme. More work is also required to understand
the fairness of split congestion control when co-existing with end-to-end or
other split schemes.

\section{Final remarks}
\label{sec:conclusion:remarks}

Sidekick protocols are a novel approach to in-network assistance for secure
transport protocols that yield performance benefits similar to those of
traditional PEPs, but leave the underlying protocol free to evolve.
The performance benefits of connection-splitting remain relevant today
especially in lossy network environments. In summary, this work contributes
new tools and directions to reimagine how endpoints and proxies can securely
collaborate to achieve a better and more performant network.
